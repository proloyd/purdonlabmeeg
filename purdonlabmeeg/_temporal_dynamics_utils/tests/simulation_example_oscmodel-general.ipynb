{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Proloy das <pd640@nmr.mgh.harvard.edu>\n",
    "# License: BSD (3-clause)\n",
    "%config InlineBackend.figure_formats = ['svg']\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import eelbrain\n",
    "import mne\n",
    "from mne.datasets import sample\n",
    "from codetiming import Timer\n",
    "from matplotlib import pyplot as plt\n",
    "from eelbrain import save\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "mne.viz.set_browser_backend('matplotlib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = sample.data_path()\n",
    "fwd_fname = os.path.join(data_path, 'MEG/sample/sample_audvis-meg-eeg-oct-6-fwd.fif')\n",
    "ave_fname = os.path.join(data_path, 'MEG/sample/sample_audvis-ave.fif')\n",
    "cov_fname = os.path.join(data_path, 'MEG/sample/sample_audvis-cov.fif')\n",
    "subjects_dir = os.path.join(data_path, 'subjects')\n",
    "condition = 'Left Auditory'\n",
    "subject = 'sample'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = mne.io.read_info(ave_fname)\n",
    "with info._unlock():\n",
    "    info['sfreq'] = 100.\n",
    "tstep = 1 / info['sfreq']\n",
    "forward = mne.read_forward_solution(fwd_fname)\n",
    "src = forward['src']\n",
    "noise_cov = mne.read_cov(cov_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_indices = mne.pick_types(info, meg=False, eeg=True, stim=True)\n",
    "info = mne.pick_info(info, eeg_indices)\n",
    "info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regions to activate\n",
    "For demonstartion purpose, we use choose four region of interests from both hemispheres.\n",
    "\n",
    "| region             | hemi | activity |\n",
    "|--------------------|------|----------|\n",
    "|transversetemporal  |  lh  |   slow   |\n",
    "|precentral          |  rh  |   slow   |\n",
    "|inferiorparietal    |  rh  |   alpha  |\n",
    "|caudalmiddlefrontal|  lh  |   alpha  |\n",
    "\n",
    "Each ROI extent is 10 mm, starting from the center of the above-mentioned DKT atlas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rois = ['transversetemporal', 'precentral', 'inferiorparietal', 'caudalmiddlefrontal']\n",
    "hemis = ['lh', 'rh', 'rh', 'lh']\n",
    "selected_labels = [mne.read_labels_from_annot(\n",
    "                                        subject,\n",
    "                                        regexp=f'{roi}-{hemi}',\n",
    "                                        subjects_dir=subjects_dir\n",
    "                                             )[0] \n",
    "                   for roi, hemi in zip(rois, hemis)]\n",
    "location = 'center'  # Use the center of the region as a seed.\n",
    "extent = 10.  # Extent in mm of the region.\n",
    "labels = [mne.label.select_sources(\n",
    "    subject, selected_label, location=location, extent=extent,\n",
    "    subjects_dir=subjects_dir) for selected_label in selected_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the time course of the activity for each source of the region to activate.\n",
    "Here we use two AR models: one slow (central frequecny 1.6Hz), and one fast oscillations (central frequency 12Hz). \n",
    "1. For slow oscillations, one of them is amiply lagged version of the another.\n",
    "2. For the fast oscillations, they are two separate realizations of the same AR process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from purdonlabmeeg._temporal_dynamics_utils.tests._generate_data import ARData\n",
    "\n",
    "ntimes = int(np.round(info['sfreq'] * 20. * 10)) + 200\n",
    "# slow_data = ARData(ntimes + 36, noise_var=0.01,\n",
    "#                    coeffs=[2*np.cos(2*np.pi*1.6/info['sfreq']),\n",
    "#                            -0.9999999],\n",
    "#                    num_prev=2)\n",
    "# fast_data = ARData(ntimes, noise_var=0.01,\n",
    "#                    coeffs=[2*np.cos(2*np.pi*12/info['sfreq']),\n",
    "#                            -0.9996],\n",
    "#                    num_prev=2)\n",
    "\n",
    "# another_fast_data = ARData(ntimes, noise_var=0.01,\n",
    "#                    coeffs=[2*np.cos(2*np.pi*10./info['sfreq']),\n",
    "#                            -0.9996],\n",
    "#                    num_prev=2)\n",
    "\n",
    "slow_data = ARData(ntimes + 1, noise_var=0.01,\n",
    "                   coeffs=[2*np.cos(2*np.pi*1.6/info['sfreq']),\n",
    "                           -0.993],\n",
    "                   num_prev=2)\n",
    "fast_data = ARData(ntimes, noise_var=0.01,\n",
    "                   coeffs=[2*np.cos(2*np.pi*12/info['sfreq']),\n",
    "                           -0.965],\n",
    "                   num_prev=2)\n",
    "\n",
    "another_fast_data = ARData(ntimes, noise_var=0.01,\n",
    "                   coeffs=[2*np.cos(2*np.pi*10./info['sfreq']),\n",
    "                           -0.96],\n",
    "                   num_prev=2)\n",
    "\n",
    "source_time_series1 = 15e-9 * slow_data.y[200:][1:] / slow_data.y[200:].std()\n",
    "source_time_series2 = 5e-9 * slow_data.y[200:][:-1] / slow_data.y[200:].std()\n",
    "source_time_series3 = 10e-9 * fast_data.y[200:] / fast_data.y[200:].std()\n",
    "source_time_series4 = 5e-9  * another_fast_data.y[200:] / another_fast_data.y[200:].std()\n",
    "source_time_serieses = (source_time_series1, source_time_series2,\n",
    "                       source_time_series3, source_time_series4)\n",
    "source_time_serieses = [x[20:] for x in source_time_serieses] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx = np.arange(ntimes-200) / info['sfreq']\n",
    "fig, ax = plt.subplots(figsize=(10, 3))\n",
    "ax.plot(tx, source_time_series1, label='leading slow data')\n",
    "ax.plot(tx, source_time_series2, label='lagging slow data')\n",
    "ax.plot(tx, source_time_series3, label='fast data')\n",
    "ax.plot(tx, source_time_series4, label='another fast data')\n",
    "ax.set_ylim([-0.5e-7, 0.5e-7])\n",
    "legend = ax.legend()\n",
    "fig.savefig('source_time_courses.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define when the activity occurs using events.<br>\n",
    "The first column is the sample of the event, the second is not used, and the third is the event id. Here the events occur every 200 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_events = 10\n",
    "events = np.zeros((n_events, 3), dtype=np.int_)\n",
    "events[:, 0] = 100 + (ntimes // 10) * np.arange(n_events)  # Events sample.\n",
    "events[:, 2] = 1  # All events have the sample id."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Simulated activity creation (kinda easy).<br>\n",
    "Here we use a `SourceSimulator` whose add_data method is the key. It allows us to specify where (label), what (source_time_series), and when (events) an event type will occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_simulator = mne.simulation.SourceSimulator(src, tstep=tstep)\n",
    "for label, source_time_series  in zip(labels, source_time_serieses):\n",
    "    source_simulator.add_data(label, source_time_series, np.array([[0, 100, 1],]))\n",
    "\n",
    "stc = source_simulator.get_stc(100, ntimes+100)\n",
    "\n",
    "def summarize(x, axis): \n",
    "    return np.sum(x ** 2, axis=axis)\n",
    "stc = stc.bin(10, func=summarize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_time = 5.4\n",
    "# brain = stc.plot(subjects_dir=subjects_dir, hemi='both', initial_time=initial_time,\n",
    "#                  clim=dict(kind='value', lims=[1e-9, 6e-9, 2e-8]), alpha=1.0,\n",
    "#                  smoothing_steps=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, the noise is kinda important, we visualize it before moving forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise_cov.data[:] *= np.eye(noise_cov.data.shape[0])\n",
    "noise_cov.data[:] += 0.2 * np.diag(np.diag(noise_cov.data))\n",
    "noise_cov.data[:] /= 1.2\n",
    "\n",
    "# fig = noise_cov.plot(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to project the source time series to sensor space and add some noise.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = mne.simulation.simulate_raw(info, source_simulator, forward=forward)\n",
    "# cov = mne.make_ad_hoc_cov(raw.info)\n",
    "raw_orig = raw.copy()\n",
    "mne.simulation.add_noise(raw, noise_cov, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract the epochs and form evoked object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# events = mne.find_events(raw)\n",
    "# raw = raw.filter(1., None)\n",
    "raw.set_eeg_reference('average', projection=True)\n",
    "epochs = mne.Epochs(raw, events, 1, tmin=-0.0, tmax=15.0, baseline=None)\n",
    "epochs.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = epochs[4:].plot_psd()\n",
    "fig.savefig('psd plot.svg')\n",
    "fig = epochs[4:].plot_psd_topomap()\n",
    "fig.savefig('psd plot topomap.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VVI: Crop timepoints of interest, and pick only the EEG channels!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epochs = epochs.pick_types(eeg=True, meg=False)\n",
    "# epochs = epochs.drop_channels('EEG 052')\n",
    "fig = epochs.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, lets look at the noise cov to remind ourselves that it is _not diagonal_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = noise_cov.plot(epochs.info)\n",
    "# fig.savefig('noise-cov.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from purdonlabmeeg.oca import OCA, OCACV\n",
    "\n",
    "oca = OCACV(n_oscillations=[2, 3, 4, 5, 6, 8, 10], n_pca_components=.9999, noise_cov=noise_cov,\n",
    "            fit_params={'ar_order':13, 'pca_whiten':False, 'scalar_alpha':True}, max_iter=100)\n",
    "oca.fit(epochs[4:6])\n",
    "# for ii in [0]: # range(0, len(epochs)):\n",
    "#     ocacv = OCA.fit(epochs[4:6], 10, picks=None, start=None, stop=None,\n",
    "#                        max_iter=50, initial_guess=None,\n",
    "#                        scalar_alpha=True, update_sigma2=True,\n",
    "#                        tol=1e-6, verbose=None, ar_order=7)\n",
    "#     save.pickle(ocacv, f'results/oca-10s-epoch{ii}-cv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = oca.plot_cv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oca._oscillators_.freq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.cov.compute_covariance(epochs).plot(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "oca.get_fitted_noise_cov().plot(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = oca.get_sources(epochs[4:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig =  sources.plot_psd(picks='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = sources.plot(picks='all', scalings={'misc': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "recon_epochs = oca.apply(epochs)\n",
    "res = epochs.copy()\n",
    "res._data -= recon_epochs._data\n",
    "fig = res.plot_psd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now that we have fitted OCA, how many osc components do you think OCA will recover? 2, 3, or 4 or more? Let's find out, shall we?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait, what? Why 3? should not there be 4. Think twice. How many independent time courses were there? \n",
    "\n",
    "Lets look at the loading matrices, i.e the topomaps now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = ocacv.plot_topomaps(plot_phase=False, colorbar=True)\n",
    "fig.savefig('oca-topomaps.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the recovered time courses?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = ocacv.plot_sources(epochs, scalings={'misc': 5e-1})\n",
    "fig.savefig('oca-tc.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How is the free energy doing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(ocacv._free_energy)\n",
    "for oca in ocacv._rest_ocas[:2]:\n",
    "    ax.plot(oca._free_energy)\n",
    "fig.savefig('oca-convg.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And last, but not the least, how was the noise covariance learing? 😲"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = ocacv.noise_cov.plot(ocacv.info)\n",
    "fig[0].savefig('oca-noise-cov-est.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # WIP\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.gridspec import GridSpec\n",
    "\n",
    "\n",
    "# def format_axes(fig):\n",
    "#     for i, ax in enumerate(fig.axes):\n",
    "# #         ax.text(0.5, 0.5, \"ax%d\" % (i+1), va=\"center\", ha=\"center\")\n",
    "#         ax.tick_params(labelbottom=False, labelleft=False)\n",
    "\n",
    "# fig = plt.figure(constrained_layout=True)\n",
    "\n",
    "# gs = GridSpec(4, 3, figure=fig)\n",
    "# ax00 = fig.add_subplot(gs[0,0], projection='3d')\n",
    "# ax01 = fig.add_subplot(gs[0,1], projection='3d')\n",
    "# ax02 = fig.add_subplot(gs[0,2], projection='3d')\n",
    "# ax1 = fig.add_subplot(gs[1, :])\n",
    "# # identical to ax1 = plt.subplot(gs.new_subplotspec((0, 0), colspan=3))\n",
    "# ax2 = fig.add_subplot(gs[2, :-1])\n",
    "# ax3 = fig.add_subplot(gs[2:, -1])\n",
    "# ax4 = fig.add_subplot(gs[-1, 0])\n",
    "# ax5 = fig.add_subplot(gs[-1, -2])\n",
    "\n",
    "# # Time courses\n",
    "# # brain = stc.plot(subjects_dir=subjects_dir, hemi='lh', initial_time=initial_time,\n",
    "# #                  clim=dict(kind='value', lims=[1e-9, 6e-9, 2e-8]), alpha=1.0,\n",
    "# #                  smoothing_steps=7, backend='matplotlib')\n",
    "\n",
    "# tx = np.arange(ntimes) / info['sfreq']\n",
    "# ax1.plot(tx, source_time_series1, label='leading slow data')\n",
    "# ax1.plot(tx, source_time_series2, label='lagging slow data')\n",
    "# ax1.plot(tx, source_time_series3, alpha=0.7, label='fast data')\n",
    "# ax1.plot(tx, source_time_series4, alpha=0.5, label='another fast data')\n",
    "# ax1.set_ylim([-0.5e-7, 0.5e-7])\n",
    "# legend = ax1.legend()\n",
    "# ax1.set_xlim([20, 40])\n",
    "\n",
    "# fig.suptitle(\"GridSpec\")\n",
    "# format_axes(fig)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WIP\n",
    "# from scipy import sparse\n",
    "# import numpy as np\n",
    "# pca, n_pca = oca._pca_dict['pca'], oca._pca_dict['n_pca']\n",
    "# noise_cov = sparse.block_diag((oca._noise_var,\n",
    "#                                 np.diag(pca.explained_variance_[n_pca:]))).toarray()\n",
    "# noise_cov = pca.inverse_transform(pca.inverse_transform(noise_cov.T).T)\n",
    "# cov = mne.Covariance(noise_cov * (ocacv._data_scale ** 2), oca.info.ch_names, \n",
    "#                      bads=None, projs=[], nfree=1, \n",
    "#                      eig=None, eigvec=None, method='custom',\n",
    "#                      loglik=None, verbose=None)\n",
    "# # epoch.info\n",
    "# cov.plot(oca.info)\n",
    "# fig.savefig('oca-noise-cov-est.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, who wants to use OCA?? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "71979f7ff8a19bcab35018ff64bd8357e6cf5e27d13107e2041642e08eefb5ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
